{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    train_data=[]\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
    "        img=~img\n",
    "        if img is not None:\n",
    "            ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "            ctrs,ret=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
    "            cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "            w=int(28)\n",
    "            h=int(28)\n",
    "            maxi=0\n",
    "            for c in cnt:\n",
    "                x,y,w,h=cv2.boundingRect(c)\n",
    "                maxi=max(w*h,maxi)\n",
    "                if maxi==w*h:\n",
    "                    x_max=x\n",
    "                    y_max=y\n",
    "                    w_max=w\n",
    "                    h_max=h\n",
    "            im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10]\n",
    "            im_resize = cv2.resize(im_crop,(28,28))\n",
    "            im_resize=np.reshape(im_resize,(784,1))\n",
    "            train_data.append(im_resize)\n",
    "    return train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33997\n"
     ]
    }
   ],
   "source": [
    "#assign '-'=10\n",
    "data=load_images_from_folder('extracted_images/-')\n",
    "len(data)\n",
    "for i in range(0,len(data)):\n",
    "    data[i]=np.append(data[i],['10'])\n",
    "    \n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59109\n"
     ]
    }
   ],
   "source": [
    "#assign + = 11\n",
    "data11=load_images_from_folder('extracted_images/+')\n",
    "\n",
    "for i in range(0,len(data11)):\n",
    "    data11[i]=np.append(data11[i],['11'])\n",
    "data=np.concatenate((data,data11))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62360\n"
     ]
    }
   ],
   "source": [
    "#assign * = 12\n",
    "data12=load_images_from_folder('extracted_images/times')\n",
    "\n",
    "for i in range(0,len(data12)):\n",
    "    data12[i]=np.append(data12[i],['12'])\n",
    "data=np.concatenate((data,data12))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63228\n"
     ]
    }
   ],
   "source": [
    "#assign / = 13\n",
    "data13=load_images_from_folder('extracted_images/div')\n",
    "\n",
    "for i in range(0,len(data13)):\n",
    "    data13[i]=np.append(data13[i],['13'])\n",
    "data=np.concatenate((data,data13))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70142\n"
     ]
    }
   ],
   "source": [
    "data0=load_images_from_folder('extracted_images/0')\n",
    "for i in range(0,len(data0)):\n",
    "    data0[i]=np.append(data0[i],['0'])\n",
    "data=np.concatenate((data,data0))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96662\n"
     ]
    }
   ],
   "source": [
    "data1=load_images_from_folder('extracted_images/1')\n",
    "\n",
    "for i in range(0,len(data1)):\n",
    "    data1[i]=np.append(data1[i],['1'])\n",
    "data=np.concatenate((data,data1))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122803\n"
     ]
    }
   ],
   "source": [
    "data2=load_images_from_folder('extracted_images/2')\n",
    "\n",
    "for i in range(0,len(data2)):\n",
    "    data2[i]=np.append(data2[i],['2'])\n",
    "data=np.concatenate((data,data2))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "133712\n"
     ]
    }
   ],
   "source": [
    "data3=load_images_from_folder('extracted_images/3')\n",
    "\n",
    "for i in range(0,len(data3)):\n",
    "    data3[i]=np.append(data3[i],['3'])\n",
    "data=np.concatenate((data,data3))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141108\n"
     ]
    }
   ],
   "source": [
    "data4=load_images_from_folder('extracted_images/4')\n",
    "\n",
    "for i in range(0,len(data4)):\n",
    "    data4[i]=np.append(data4[i],['4'])\n",
    "data=np.concatenate((data,data4))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144653\n"
     ]
    }
   ],
   "source": [
    "data5=load_images_from_folder('extracted_images/5')\n",
    "\n",
    "for i in range(0,len(data5)):\n",
    "    data5[i]=np.append(data5[i],['5'])\n",
    "data=np.concatenate((data,data5))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147771\n"
     ]
    }
   ],
   "source": [
    "data6=load_images_from_folder('extracted_images/6')\n",
    "\n",
    "for i in range(0,len(data6)):\n",
    "    data6[i]=np.append(data6[i],['6'])\n",
    "data=np.concatenate((data,data6))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150680\n"
     ]
    }
   ],
   "source": [
    "data7=load_images_from_folder('extracted_images/7')\n",
    "\n",
    "for i in range(0,len(data7)):\n",
    "    data7[i]=np.append(data7[i],['7'])\n",
    "data=np.concatenate((data,data7))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153748\n"
     ]
    }
   ],
   "source": [
    "data8=load_images_from_folder('extracted_images/8')\n",
    "\n",
    "for i in range(0,len(data8)):\n",
    "    data8[i]=np.append(data8[i],['8'])\n",
    "data=np.concatenate((data,data8))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157485\n"
     ]
    }
   ],
   "source": [
    "data9=load_images_from_folder('extracted_images/9')\n",
    "for i in range(0,len(data9)):\n",
    "    data9[i]=np.append(data9[i],['9'])\n",
    "data=np.concatenate((data,data9))\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    merge all symbols and digits into one data frame\n",
    "    save this as csv file, which will be used later for training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(data,index=None)\n",
    "df.to_csv('train_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('train_data.csv',index_col=False)\n",
    "labels=df_train[['784']]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_train.drop(df_train.columns[[784]],axis=1,inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1212)\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "labels=np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "cat = np_utils.to_categorical(labels, num_classes = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(cat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "l=[]\n",
    "for i in range(168394):\n",
    "    l.append(np.array(df_train[i:i+1]).reshape(28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(30, (5, 5), input_shape=(28, 28, 1), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(15, (3,3), activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(14, activation='softmax'))\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(np.array(l).shape)\n",
    "print(cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model.fit(np.array(l), cat, batch_size=200, epochs=10, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_trained.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_trained.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "json_file = open('model_trained.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_trained.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('/Users/asad/Desktop/All Folders/Files/Engineering/SEM 6/Artificial Intelligence/Lab/EquationRecognition/test2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "#kernel = np.ones((3,3),np.uint8)\n",
    "cv2.imshow(\"wo\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "#erosion = cv2.erode(img,kernel,iterations = 3)\n",
    "#dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "#img=dilation\n",
    "if img is not None:\n",
    "    #images.append(img)\n",
    "    img=~img\n",
    "    ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
    "    ctrs,ret=cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "    w=int(28)\n",
    "    h=int(28)\n",
    "    train_data=[]\n",
    "    #print(len(cnt))\n",
    "    rects=[]\n",
    "    for c in cnt :\n",
    "        x,y,w,h= cv2.boundingRect(c)\n",
    "        rect=[x,y,w,h]\n",
    "        rects.append(rect)\n",
    "    #print(rects)\n",
    "    bool_rect=[]\n",
    "    for r in rects:\n",
    "        l=[]\n",
    "        for rec in rects:\n",
    "            flag=0\n",
    "            if rec!=r:\n",
    "                if r[0]<(rec[0]+rec[2]+10) and rec[0]<(r[0]+r[2]+10) and r[1]<(rec[1]+rec[3]+10) and rec[1]<(r[1]+r[3]+10):\n",
    "                    flag=1\n",
    "                l.append(flag)\n",
    "            if rec==r:\n",
    "                l.append(0)\n",
    "        bool_rect.append(l)\n",
    "    #print(bool_rect)\n",
    "    dump_rect=[]\n",
    "    for i in range(0,len(cnt)):\n",
    "        for j in range(0,len(cnt)):\n",
    "            if bool_rect[i][j]==1:\n",
    "                area1=rects[i][2]*rects[i][3]\n",
    "                area2=rects[j][2]*rects[j][3]\n",
    "                if(area1==min(area1,area2)):\n",
    "                    dump_rect.append(rects[i])\n",
    "    #print(len(dump_rect)) \n",
    "    final_rect=[i for i in rects if i not in dump_rect]\n",
    "    #print(final_rect)\n",
    "    for r in final_rect:\n",
    "        x=r[0]\n",
    "        y=r[1]\n",
    "        w=r[2]\n",
    "        h=r[3]\n",
    "        im_crop =thresh[y:y+h+10,x:x+w+10]\n",
    "        \n",
    "\n",
    "        im_resize = cv2.resize(im_crop,(28,28))\n",
    "        cv2.imshow(\"work\",im_resize)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        im_resize=np.reshape(im_resize,(28,28,1))\n",
    "        train_data.append(im_resize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tf.autograph.experimental.do_not_convert\n",
    "s=''\n",
    "for i in range(len(train_data)):\n",
    "    train_data[i]=np.array(train_data[i])\n",
    "    train_data[i]=train_data[i].reshape(1,28,28,1)\n",
    "    result=loaded_model.predict_classes(train_data[i])\n",
    "    if(result[0]==10):\n",
    "        s=s+'-'\n",
    "    if(result[0]==11):\n",
    "        s=s+'+'\n",
    "    if(result[0]==12):\n",
    "        s=s+'*'\n",
    "    if(result[0]==13):\n",
    "        s=s+'/'\n",
    "    if(result[0]==0): \n",
    "        s=s+'0'\n",
    "    if(result[0]==1):\n",
    "        s=s+'1'\n",
    "    if(result[0]==2):\n",
    "        s=s+'2'\n",
    "    if(result[0]==3):\n",
    "        s=s+'3'\n",
    "    if(result[0]==4):\n",
    "        s=s+'4'\n",
    "    if(result[0]==5):\n",
    "        s=s+'5'\n",
    "    if(result[0]==6):\n",
    "        s=s+'6'\n",
    "    if(result[0]==7):\n",
    "        s=s+'7'\n",
    "    if(result[0]==8):\n",
    "        s=s+'8'\n",
    "    if(result[0]==9):\n",
    "        s=s+'9'\n",
    "    \n",
    "print(s)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "eval(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}